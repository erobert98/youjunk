from pythonwhois import get_whois
from app import db
from app.db_util_website import *
import feedparser
import json
from newspaper import Article as NA
from pprint import pprint
from bs4 import BeautifulSoup



def find_body(url):
	article = NA(url)
	article.download()
	article.parse()
	body = article.text 
	return body

def parse_websiteArticles(feed, websiteURL):
	data = feedparser.parse(feed)
	feed_articles = (len(data['items']))
	item = 0
	while item < feed_articles:
			title = data['items'][item]['title']
			description = data['items'][item]['description']
			link = data['items'][item]['link']
			print(link)
			link2 = str(link)
			date = str(data['items'][item]['published'])
			author = json.dumps(data['items'][0]['authors'])
			print(f"title : {title}  description :{description}, link : {link}, date :{date}, author : {author}")
			# data['items'][item]['title']
			body = find_body(link)
			wid = find_website(websiteURL)
			save_articleInfo(title, description, link, date, author, wid, body)
			item += 1


def get_domainInfo(url):
	w = get_whois(url)
	creation_date = w['creation_date']
	return creation_date

	
	















































































































































































































































































































































































































































